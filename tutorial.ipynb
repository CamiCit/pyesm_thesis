{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "PACKAGE LOCAL INSTALLATION and USAGE\n",
    "\n",
    "Editable local installation:\n",
    "1. Create a virtual environment based on 'environment.yml' file.\n",
    "2. In the cmd, run: >>> python -m pip install -e \"path/to/pyesm\"\n",
    "3. From the virtual environment: >>> import esm\n",
    "4. Use esm APIs (Model class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- - - \n",
    "MODEL DIRECTORY GENERATION\n",
    "\n",
    "Generation of a model directory based on a model template or with blank setup files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model directory with essential setup files\n",
    "# to be used only to generate models from scratch\n",
    "# template models can be imported \n",
    "import esm\n",
    "\n",
    "model_dir_name = 'test'\n",
    "main_dir_path = 'D:\\Politecnico di Milano\\Documentale DENG - PRIN-MIMO\\Models\\pyESM_docs\\case_studies'\n",
    "\n",
    "esm.create_model_dir(\n",
    "    model_dir_name=model_dir_name,\n",
    "    main_dir_path=main_dir_path,\n",
    "    default_model='1_sut',\n",
    "    force_overwrite=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - - \n",
    "GENERATION OF A NEW MODEL FROM SCRATCH\n",
    "\n",
    "Generation of a new model defined by setup files.\n",
    "\n",
    "Step-by-step model creation with sets, data and problems generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate model instance based on setup files filled by the user.\n",
    "# validates model directory before executing.\n",
    "import esm\n",
    "\n",
    "model_dir_name = 'test'\n",
    "main_dir_path = 'D:\\Politecnico di Milano\\Documentale DENG - PRIN-MIMO\\Models\\pyESM_docs\\case_studies'\n",
    "\n",
    "model = esm.Model(\n",
    "    model_dir_name=model_dir_name,\n",
    "    main_dir_path=main_dir_path,\n",
    "    use_existing_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after filling sets.xlsx file: \n",
    "# - loading model coordinates to Index\n",
    "# - generating sqlite database tables for sets and variables\n",
    "# (variables tables in sqlite database empty)\n",
    "# (error occurring at the first run related to foreign_keys. second run works)\n",
    "model.load_model_coordinates()\n",
    "model.initialize_blank_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after filling input_data file/s:\n",
    "# - loading input data into sqlite database variables tables\n",
    "# - initialize problem\n",
    "model.load_data_files_to_database()\n",
    "model.initialize_problems()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - - \n",
    "MODEL GENERATION FROM EXISTING DATA\n",
    "\n",
    "Generation of a new model working with existing database and data input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate model instance based on setup files filled by the user.\n",
    "# validates model directory (in case user relies on existing directory). \n",
    "# parse settings and paths.\n",
    "# loading model coordinates\n",
    "# initializing numerical problem\n",
    "import esm \n",
    "\n",
    "model_dir_name = 'test'\n",
    "main_dir_path = 'D:\\Politecnico di Milano\\Documentale DENG - PRIN-MIMO\\Models\\pyESM_docs\\case_studies'\n",
    "\n",
    "model = esm.Model(\n",
    "    model_dir_name=model_dir_name,\n",
    "    main_dir_path=main_dir_path,\n",
    "    use_existing_data=True,\n",
    "    log_level='debug'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "DATA and MODEL UPDATE, MODEL RUN \n",
    "\n",
    "updating SQLite database with new data, \n",
    "re-initializing numerical problem\n",
    "\n",
    "solving numerical model, \n",
    "results export to sqlite database, \n",
    "generation of powerbi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case of modifications in input data files (not in sets),\n",
    "# update database and problem\n",
    "model.update_database_and_problem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case of modifications in symbolic problem,\n",
    "# update problems dataframe and symbolic problem\n",
    "model.initialize_problems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve numerical problems\n",
    "model.run_model(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once model has successfully solved, load endogenous parameters data to \n",
    "# sqlite database and generate powerbi dataset.\n",
    "model.load_results_to_database()\n",
    "model.generate_pbi_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - - \n",
    "TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.core.index.sets.technologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.core.problem.symbolic_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.core.problem.numeric_problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "# Problem data.\n",
    "m = 10\n",
    "n = 5\n",
    "\n",
    "# Construct the problem.\n",
    "x = cp.Variable((n,1))\n",
    "A = cp.Constant(np.random.randn(m, n))\n",
    "b = cp.Constant(1)\n",
    "\n",
    "\n",
    "L = cp.Variable((n,n))\n",
    "C = cp.Constant(np.random.randn(n, n))\n",
    "I = cp.Constant(np.eye(n))\n",
    "\n",
    "objective = cp.Minimize(cp.sum_squares(A @ x - b))\n",
    "constraints = [0 <= x, x <= 1]\n",
    "prob = cp.Problem(objective, constraints)\n",
    "\n",
    "# The optimal objective value is returned by `prob.solve()`.\n",
    "result = prob.solve(solver='GUROBI', verbose=False)\n",
    "# The optimal value for x is stored in `x.value`.\n",
    "\n",
    "prob.status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINIZIONE COSTANTI PER TRASFORMARE I VARI OPERATORI VETTORIALI\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "var_a = cp.Variable((3,2))\n",
    "var_a.value = np.ones((var_a.shape))*3\n",
    "var_b = cp.Variable((3,1))\n",
    "\n",
    "i_21 = cp.Constant(np.ones((2,1)))\n",
    "i_13 = cp.Constant(np.ones((1,3)))\n",
    "\n",
    "allowed_vars = {\n",
    "    'A': var_a,\n",
    "    'B': var_b,\n",
    "    'i_21': i_21,\n",
    "    'i_13': i_13,\n",
    "}\n",
    "\n",
    "allowed_ops = {\n",
    "    '+': '+',\n",
    "    '-': '-',\n",
    "    '*': '*',\n",
    "    '@': '@',\n",
    "    '==': '==',\n",
    "    '>=': '>=',\n",
    "    '<=': '<=',\n",
    "    '(': '(',\n",
    "    ')': ')',\n",
    "    ',':',',\n",
    "    'sum': cp.sum,\n",
    "}\n",
    "\n",
    "expr = model.core.problem.execute_cvxpy_code(\n",
    "    expression='i_13 @ A @ i_21',\n",
    "    allowed_variables=allowed_vars,\n",
    "    allowed_operators=allowed_ops\n",
    ")\n",
    "\n",
    "expr2 = model.core.problem.execute_cvxpy_code(\n",
    "    expression='sum(B)',\n",
    "    allowed_variables=allowed_vars,\n",
    "    allowed_operators=allowed_ops\n",
    ")\n",
    "\n",
    "expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from esm.util import constants\n",
    "from esm.util import util\n",
    "\n",
    "field_id = constants._STD_ID_FIELD['id'][0]\n",
    "\n",
    "col_to_update = constants._STD_VALUES_FIELD['values'][0]\n",
    "cols_common = list(variable.coordinates.keys())\n",
    "\n",
    "new_df = variable.reshaping_variable_data(0)\n",
    "\n",
    "new_values = {\n",
    "    's_Name': 'Reference',\n",
    "    'dt_Name': '2023',\n",
    "    't_Name': 'Final demand',\n",
    "    'values': 15.0\n",
    "}\n",
    "\n",
    "new_df.loc[len(new_df)] = new_values\n",
    "new_df.at[0,'values'] = 2\n",
    "\n",
    "test.core.sqltools.open_connection()\n",
    "existing_df = test.core.sqltools.table_to_dataframe(table_name=variable.symbol)\n",
    "existing_df.drop(columns=['id'],inplace=True)\n",
    "test.core.sqltools.close_connection()\n",
    "\n",
    "print('\\n')\n",
    "print('existing_df: \\n', existing_df)\n",
    "print('\\n')\n",
    "print('new_df: \\n', new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable=test.core.index.variables.u\n",
    "\n",
    "test.core.database.sqltools.open_connection()\n",
    "raw_data = test.core.database.sqltools.filtered_table_to_dataframe(\n",
    "    table_name=variable.symbol,\n",
    "    filters_dict=variable.data['filter'][0]\n",
    ")\n",
    "test.core.database.sqltools.close_connection()\n",
    "\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.core.database.sqltools.open_connection()\n",
    "\n",
    "var = test.core.database.sqltools.filtered_table_to_dataframe(\n",
    "    table_name='u',\n",
    "    filters_dict={\n",
    "        's_Name': ['Reference'],\n",
    "        'dt_Name': [2023],\n",
    "        'f_Name': ['Energy', 'Steel'],\n",
    "        't_Name': ['PV power plant', 'Steel factory', 'Gas power plant']\n",
    "    }\n",
    ")\n",
    "\n",
    "# filter_1 = test.core.database.sqltools.get_related_table_keys(\n",
    "#     child_column_name='f_Name',\n",
    "#     parent_table_name='_set_FLOWS',\n",
    "#     parent_table_fields={\n",
    "#         'f_Category': ['Product flow'],\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# filter_2 = test.core.database.sqltools.get_related_table_keys(\n",
    "#     child_column_name='dt_Name',\n",
    "#     parent_table_name='_set_DATETIME',\n",
    "#     parent_table_fields={\n",
    "#         'dt_Name': [2023],\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# var_custom_filter = test.core.database.sqltools.filtered_table_to_dataframe(\n",
    "#     table_name='v',\n",
    "#     filters_dict={\n",
    "#         **filter_1,\n",
    "#         **filter_2,\n",
    "#         **{'f_Name': ['Steel']},\n",
    "#     }\n",
    "# )\n",
    "\n",
    "test.core.database.sqltools.close_connection()\n",
    "\n",
    "# filter_1, filter_2\n",
    "var"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
