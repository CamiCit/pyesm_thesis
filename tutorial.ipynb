{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyESM - Python based Engineering Systems Modelling (pyESM)\n",
    "Python based engineering systems modelling framework based on the Supply and Use structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "PACKAGE LOCAL INSTALLATION and USAGE\n",
    "\n",
    "Editable local installation:\n",
    "1. Create a virtual environment based on 'environment.yml' file.\n",
    "2. In the cmd, run: >>> python -m pip install -e \"path/to/pyesm\"\n",
    "3. From the virtual environment: >>> import esm\n",
    "4. Use esm APIs (Model class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "CREATE/UPDATE ENVIRONMENT BASED ON YML FILE IN PROJECT REPO\n",
    "\n",
    "In the prompt:\n",
    "- From the path where environment.yml is present: >>> conda env create -f environment.yml\n",
    "- The environment is named \"esm\", so type >>> conda activate esm\n",
    "\n",
    "UPDATE ENVIRONMENT YML FILE (in case of modifications)\n",
    "\n",
    "In the prompt: \n",
    "- activate the working environment: >>> conda activate your_environment_name\n",
    "- export environment.yml file based on the working environment: >>> conda env export > environment.yml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- - - \n",
    "MODEL DIRECTORY GENERATION\n",
    "\n",
    "Generation of a model directory based on a model template or with blank setup files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model directory with essential setup files\n",
    "# to be used only to generate models from scratch\n",
    "# template models can be imported \n",
    "import esm\n",
    "\n",
    "model_dir_name = '2_multi_year'\n",
    "main_dir_path = 'D:\\git_repos\\pyesm\\default'\n",
    "\n",
    "esm.create_model_dir(\n",
    "    model_dir_name=model_dir_name,\n",
    "    main_dir_path=main_dir_path,\n",
    "    default_model=None,\n",
    "    force_overwrite=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - - \n",
    "GENERATION OF A NEW MODEL FROM SCRATCH\n",
    "\n",
    "Generation of a new model defined by setup files.\n",
    "\n",
    "Step-by-step model creation with sets, data and problems generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | Model | 'Model' object initialization...\n",
      "INFO | Model.file_manager | 'FileManager' object generated.\n",
      "INFO | Model | Defining settings from model arguments.\n",
      "INFO | Model | Defining paths from model arguments.\n",
      "INFO | Model | Model directory and required setup files validated.\n",
      "INFO | Model.core | 'Core' object initialization...\n",
      "INFO | Model.core.sql_manager | 'SQLManager' object generation.\n",
      "INFO | Model.core.index | 'Index' object initialization...\n",
      "DEBUG | Model.file_manager | File 'sets_structure.yml' loaded.\n",
      "DEBUG | Model.file_manager | File 'variables.yml' loaded.\n",
      "DEBUG | Model.core.index | Loading 'variables_fields' to Index.\n",
      "DEBUG | Model.core.index | Loading variables 'table_headers' to Index.\n",
      "DEBUG | Model.core.index | Loading variables 'sets_parsing_hierarchy' to Index.\n",
      "INFO | Model.core.index | 'Index' object initialized.\n",
      "INFO | Model.core.database | 'Database' object initialization...\n",
      "DEBUG | Model.core.sql_manager | Connection to 'database.db' opened.\n",
      "INFO | Model.core.database | Overwriting database 'database.db'\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_SCENARIOS' - created.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_SENSITIVITY' - created.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_TIME' - created.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_STOCKS' - created.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_TECHNOLOGIES' - created.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_FLOWS' - created.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_TECHNICAL_SPECS' - created.\n",
      "DEBUG | Model.core.sql_manager | Connection to 'database.db' closed.\n",
      "DEBUG | Model.core.sql_manager | Connection to 'database.db' opened.\n",
      "INFO | Model.core.database | Generating new sets excel file 'sets.xlsx'\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_SCENARIOS' - exported to sets.xlsx.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_SENSITIVITY' - exported to sets.xlsx.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_TIME' - exported to sets.xlsx.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_STOCKS' - exported to sets.xlsx.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_TECHNOLOGIES' - exported to sets.xlsx.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_FLOWS' - exported to sets.xlsx.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_TECHNICAL_SPECS' - exported to sets.xlsx.\n",
      "DEBUG | Model.core.sql_manager | Connection to 'database.db' closed.\n",
      "INFO | Model.core.database | 'Database' object initialized.\n",
      "INFO | Model.core.problem | 'Problem' object initialization...\n",
      "INFO | Model.core.problem | 'Problem' object initialized.\n",
      "INFO | Model.core | 'Core' initialized.\n",
      "INFO | Model.pbi_manager | 'PBIManager' object generated.\n",
      "INFO | Model | 'Model' object initialized.\n"
     ]
    }
   ],
   "source": [
    "# generate model instance based on setup files filled by the user.\n",
    "# validates model directory before executing.\n",
    "import esm\n",
    "\n",
    "model_dir_name = '2_multi_year'\n",
    "main_dir_path = 'D:\\git_repos\\pyesm\\default'\n",
    "\n",
    "model = esm.Model(\n",
    "    model_dir_name=model_dir_name,\n",
    "    main_dir_path=main_dir_path,\n",
    "    use_existing_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | Model | Loading new sets data and variable coordinates.\n",
      "WARNING | Model.core.index | 'Index' object: Sets tables already defined for at least one Set in Index.\n",
      "INFO | Model.core.index | 'Index' object: Sets tables not overwritten.\n",
      "DEBUG | Model.core.index | Loading variables 'coordinates' to Index.\n",
      "DEBUG | Model.core.index | Loading tables 'foreign_keys' to Index.\n",
      "INFO | Model | Generating blank SQLite database and excel input files.\n",
      "DEBUG | Model.core.sql_manager | Connection to 'database.db' opened.\n",
      "INFO | Model.core.database | Loading Sets to 'database.db'.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_SCENARIOS' - NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_SCENARIOS' - original data NOT erased.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_SENSITIVITY' - NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_SENSITIVITY' - original data NOT erased.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_TIME' - NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_TIME' - original data NOT erased.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_STOCKS' - NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_STOCKS' - original data NOT erased.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_TECHNOLOGIES' - NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_TECHNOLOGIES' - original data NOT erased.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_FLOWS' - NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_FLOWS' - original data NOT erased.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_TECHNICAL_SPECS' - NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table '_set_TECHNICAL_SPECS' - original data NOT erased.\n",
      "DEBUG | Model.core.sql_manager | Connection to 'database.db' closed.\n",
      "DEBUG | Model.core.sql_manager | Connection to 'database.db' opened.\n",
      "INFO | Model.core.database | Generation of empty SQLite database variables tables.\n",
      "DEBUG | Model.core.sql_manager | SQLite table 'u' already exists.\n",
      "DEBUG | Model.core.sql_manager | SQLlite table 'u' NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table 'd' already exists.\n",
      "DEBUG | Model.core.sql_manager | SQLlite table 'd' NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table 'Y' already exists.\n",
      "DEBUG | Model.core.sql_manager | SQLlite table 'Y' NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table 'cap_oi' already exists.\n",
      "DEBUG | Model.core.sql_manager | SQLlite table 'cap_oi' NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table 'c_op_spec' already exists.\n",
      "DEBUG | Model.core.sql_manager | SQLlite table 'c_op_spec' NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table 'c_ca_spec' already exists.\n",
      "DEBUG | Model.core.sql_manager | SQLlite table 'c_ca_spec' NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table 'ts_max' already exists.\n",
      "DEBUG | Model.core.sql_manager | SQLlite table 'ts_max' NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table 'ts_min' already exists.\n",
      "DEBUG | Model.core.sql_manager | SQLlite table 'ts_min' NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table 'Q' already exists.\n",
      "DEBUG | Model.core.sql_manager | SQLlite table 'Q' NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table 'Q_agg' already exists.\n",
      "DEBUG | Model.core.sql_manager | SQLlite table 'Q_agg' NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table 'X' already exists.\n",
      "DEBUG | Model.core.sql_manager | SQLlite table 'X' NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table 'cap_n' already exists.\n",
      "DEBUG | Model.core.sql_manager | SQLlite table 'cap_n' NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table 'cap_o' already exists.\n",
      "DEBUG | Model.core.sql_manager | SQLlite table 'cap_o' NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table 'C_op' already exists.\n",
      "DEBUG | Model.core.sql_manager | SQLlite table 'C_op' NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | SQLite table 'C_ca' already exists.\n",
      "DEBUG | Model.core.sql_manager | SQLlite table 'C_ca' NOT overwritten.\n",
      "DEBUG | Model.core.sql_manager | Connection to 'database.db' closed.\n",
      "DEBUG | Model.core.sql_manager | Connection to 'database.db' opened.\n",
      "INFO | Model.core.database | Filling empty SQLite database variables tables with sets data.\n",
      "ERROR | Model.core.sql_manager | Passed DataFrame and SQLite table 'u' headers mismatch.\n",
      "DEBUG | Model.core.sql_manager | Connection to 'database.db' closed.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Passed DataFrame and SQLite table 'u' headers mismatch.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# after filling sets.xlsx file: \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# - loading model coordinates to Index\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# - generating sqlite database tables for sets and variables\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# (variables tables in sqlite database empty)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mload_model_coordinates()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_blank_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\git_repos\\pyesm\\esm\\base\\model.py:134\u001b[0m, in \u001b[0;36mModel.initialize_blank_database\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mdatabase\u001b[38;5;241m.\u001b[39mload_sets_to_database()\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mdatabase\u001b[38;5;241m.\u001b[39mgenerate_blank_vars_sql_tables()\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mdatabase\u001b[38;5;241m.\u001b[39msets_data_to_vars_sql_tables()\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mdatabase\u001b[38;5;241m.\u001b[39mgenerate_blank_tables_input_files()\n",
      "File \u001b[1;32md:\\git_repos\\pyesm\\esm\\support\\sql_manager.py:822\u001b[0m, in \u001b[0;36mconnection.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqltools\u001b[38;5;241m.\u001b[39mopen_connection()\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 822\u001b[0m     result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqltools\u001b[38;5;241m.\u001b[39mclose_connection()\n",
      "File \u001b[1;32md:\\git_repos\\pyesm\\esm\\base\\database.py:144\u001b[0m, in \u001b[0;36mDatabase.sets_data_to_vars_sql_tables\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m unpivoted_coords_df \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39munpivot_dict_to_dataframe(\n\u001b[0;32m    134\u001b[0m     data_dict\u001b[38;5;241m=\u001b[39mvariable\u001b[38;5;241m.\u001b[39mcoordinates,\n\u001b[0;32m    135\u001b[0m     key_order\u001b[38;5;241m=\u001b[39mtable_headers_list\n\u001b[0;32m    136\u001b[0m )\n\u001b[0;32m    138\u001b[0m unpivoted_coords_df\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m    139\u001b[0m     loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    140\u001b[0m     column\u001b[38;5;241m=\u001b[39mvariable\u001b[38;5;241m.\u001b[39mtable_headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    141\u001b[0m     value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    142\u001b[0m )\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqltools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe_to_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpivoted_coords_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqltools\u001b[38;5;241m.\u001b[39madd_table_column(\n\u001b[0;32m    150\u001b[0m     table_name\u001b[38;5;241m=\u001b[39mvar_key,\n\u001b[0;32m    151\u001b[0m     column_name\u001b[38;5;241m=\u001b[39mconstants\u001b[38;5;241m.\u001b[39m_STD_VALUES_FIELD[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    152\u001b[0m     column_type\u001b[38;5;241m=\u001b[39mconstants\u001b[38;5;241m.\u001b[39m_STD_VALUES_FIELD[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    153\u001b[0m )\n",
      "File \u001b[1;32md:\\git_repos\\pyesm\\esm\\support\\sql_manager.py:564\u001b[0m, in \u001b[0;36mSQLManager.dataframe_to_table\u001b[1;34m(self, table_name, dataframe, operation, force_operation)\u001b[0m\n\u001b[0;32m    561\u001b[0m util\u001b[38;5;241m.\u001b[39mvalidate_selection(valid_operations, operation)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_table_exists(table_name)\n\u001b[1;32m--> 564\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_table_dataframe_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m table_fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_table_fields(table_name)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    567\u001b[0m num_entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount_table_data_entries(table_name)\n",
      "File \u001b[1;32md:\\git_repos\\pyesm\\esm\\support\\sql_manager.py:456\u001b[0m, in \u001b[0;36mSQLManager.validate_table_dataframe_headers\u001b[1;34m(self, table_name, dataframe, check_id_field)\u001b[0m\n\u001b[0;32m    454\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassed DataFrame and SQLite table \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m headers mismatch.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(msg)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Passed DataFrame and SQLite table 'u' headers mismatch."
     ]
    }
   ],
   "source": [
    "# after filling sets.xlsx file: \n",
    "# - loading model coordinates to Index\n",
    "# - generating sqlite database tables for sets and variables\n",
    "# (variables tables in sqlite database empty)\n",
    "model.load_model_coordinates()\n",
    "model.initialize_blank_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['I', 'T', 'u', 'd', 'Y', 'cap_oi', 'c_op_spec', 'c_ca_spec', 'ts_max', 'ts_min', 'Q', 'Q_agg', 'X', 'cap_n', 'cap_o', 'C_op', 'C_ca'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.core.index.variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after filling input_data file/s:\n",
    "# - loading input data into sqlite database variables tables\n",
    "# - initialize problem\n",
    "model.load_data_files_to_database()\n",
    "model.initialize_problems()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - - \n",
    "MODEL GENERATION FROM EXISTING DATA\n",
    "\n",
    "Generation of a new model working with existing database and data input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate model instance based on setup files filled by the user.\n",
    "# validates model directory (in case user relies on existing directory). \n",
    "# parse settings and paths.\n",
    "# loading model coordinates\n",
    "# initializing numerical problem\n",
    "import esm \n",
    "\n",
    "model_dir_name = '4_var_test'\n",
    "main_dir_path = 'D:\\git_repos\\pyesm\\default'\n",
    "\n",
    "model = esm.Model(\n",
    "    model_dir_name=model_dir_name,\n",
    "    main_dir_path=main_dir_path,\n",
    "    use_existing_data=True,\n",
    "    log_level='debug'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "DATA and MODEL UPDATE, MODEL RUN \n",
    "\n",
    "updating SQLite database with new data, \n",
    "re-initializing numerical problem\n",
    "\n",
    "solving numerical model, \n",
    "results export to sqlite database, \n",
    "generation of powerbi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case of modifications in input data files (not in sets),\n",
    "# update database and problem\n",
    "model.update_database_and_problem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case of modifications in symbolic problem,\n",
    "# update problems dataframe and symbolic problem\n",
    "model.initialize_problems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve numerical problems\n",
    "model.run_model(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once model has successfully solved, load endogenous parameters data to \n",
    "# sqlite database and generate powerbi dataset.\n",
    "model.load_results_to_database()\n",
    "model.generate_pbi_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - - \n",
    "TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.core.index.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.core.index.sets.technologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.core.problem.symbolic_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.core.problem.numeric_problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "# Problem data.\n",
    "m = 5\n",
    "n = 2\n",
    "\n",
    "# Construct the problem.\n",
    "x = cp.Variable((n,1))\n",
    "A = cp.Constant(np.random.randn(m, n))\n",
    "b = cp.Constant(1)\n",
    "\n",
    "\n",
    "C = cp.Constant(np.random.randn(n, n))\n",
    "I = cp.Constant(np.eye(n))\n",
    "\n",
    "objective = cp.Minimize(cp.sum_squares(A @ x - b))\n",
    "constraints = [0 <= x, x <= 1]\n",
    "prob = cp.Problem(objective, constraints)\n",
    "\n",
    "# The optimal objective value is returned by `prob.solve()`.\n",
    "result = prob.solve(solver='GUROBI', verbose=False)\n",
    "# The optimal value for x is stored in `x.value`.\n",
    "\n",
    "XX = cp.Variable((n,1))\n",
    "AA = cp.Constant(np.random.randn(n, m))\n",
    "\n",
    "cp.multiply(XX,AA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_24 = cp.Variable((2,4))\n",
    "c_24 = cp.Constant(np.ones((2,4)))\n",
    "c_41 = cp.Constant(np.ones((4,1)))\n",
    "\n",
    "constraints = [v_24 == c_24 + c_41.T]\n",
    "prob = cp.Problem(cp.Minimize(1), constraints)\n",
    "prob.solve(solver='GUROBI', verbose=False)\n",
    "\n",
    "print(f'v_24 = {v_24.value} \\n')\n",
    "print(f'c_24 = {c_24.value} \\n')\n",
    "print(f'c_41 = {c_41.T.value} \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINIZIONE COSTANTI PER TRASFORMARE I VARI OPERATORI VETTORIALI\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "var_a = cp.Variable((3,2))\n",
    "var_a.value = np.ones((var_a.shape))*3\n",
    "var_b = cp.Variable((3,1))\n",
    "\n",
    "i_21 = cp.Constant(np.ones((2,1)))\n",
    "i_13 = cp.Constant(np.ones((1,3)))\n",
    "\n",
    "allowed_vars = {\n",
    "    'A': var_a,\n",
    "    'B': var_b,\n",
    "    'i_21': i_21,\n",
    "    'i_13': i_13,\n",
    "}\n",
    "\n",
    "allowed_ops = {\n",
    "    '+': '+',\n",
    "    '-': '-',\n",
    "    '*': '*',\n",
    "    '@': '@',\n",
    "    '==': '==',\n",
    "    '>=': '>=',\n",
    "    '<=': '<=',\n",
    "    '(': '(',\n",
    "    ')': ')',\n",
    "    ',':',',\n",
    "    'sum': cp.sum,\n",
    "}\n",
    "\n",
    "expr = model.core.problem.execute_cvxpy_code(\n",
    "    expression='i_13 @ A @ i_21',\n",
    "    allowed_variables=allowed_vars,\n",
    "    allowed_operators=allowed_ops\n",
    ")\n",
    "\n",
    "expr2 = model.core.problem.execute_cvxpy_code(\n",
    "    expression='sum(B)',\n",
    "    allowed_variables=allowed_vars,\n",
    "    allowed_operators=allowed_ops\n",
    ")\n",
    "\n",
    "expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.core.database.sqltools.open_connection()\n",
    "\n",
    "var = model.core.database.sqltools.filtered_table_to_dataframe(\n",
    "    table_name='u',\n",
    "    filters_dict={\n",
    "        's_Name': ['Reference'],\n",
    "        'dt_Name': [2023],\n",
    "        'f_Name': ['Energy', 'Steel'],\n",
    "        't_Name': ['PV power plant', 'Steel factory', 'Gas power plant']\n",
    "    }\n",
    ")\n",
    "\n",
    "# filter_1 = test.core.database.sqltools.get_related_table_keys(\n",
    "#     child_column_name='f_Name',\n",
    "#     parent_table_name='_set_FLOWS',\n",
    "#     parent_table_fields={\n",
    "#         'f_Category': ['Product flow'],\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# filter_2 = test.core.database.sqltools.get_related_table_keys(\n",
    "#     child_column_name='dt_Name',\n",
    "#     parent_table_name='_set_DATETIME',\n",
    "#     parent_table_fields={\n",
    "#         'dt_Name': [2023],\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# var_custom_filter = test.core.database.sqltools.filtered_table_to_dataframe(\n",
    "#     table_name='v',\n",
    "#     filters_dict={\n",
    "#         **filter_1,\n",
    "#         **filter_2,\n",
    "#         **{'f_Name': ['Steel']},\n",
    "#     }\n",
    "# )\n",
    "\n",
    "model.core.database.sqltools.close_connection()\n",
    "\n",
    "# filter_1, filter_2\n",
    "var"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
