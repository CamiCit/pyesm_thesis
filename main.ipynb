{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- - - \n",
    "MODEL GENERATION FROM SCRATCH\n",
    "\n",
    "Generation of a new model from scratch, including database and data input\n",
    "\n",
    "(settings -> model -> use_existing_data -> False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model directory with essential setup files\n",
    "# to be used only to generate models from scratch\n",
    "from src.frontend import esm\n",
    "\n",
    "model_dir_name = '0_hsut'\n",
    "main_dir_path = 'D:\\Politecnico di Milano\\Documentale DENG - PRIN-MIMO\\Models\\pyESM_docs\\case_studies'\n",
    "\n",
    "esm.create_model_dir(\n",
    "    model_dir_name=model_dir_name,\n",
    "    main_dir_path=main_dir_path,\n",
    "    force_overwrite=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate model instance based on setup files filled by the user.\n",
    "# validates model directory (in case user relies on existing directory). \n",
    "# parse settings and paths.\n",
    "from src.frontend import esm\n",
    "\n",
    "model_dir_name = '0_hsut'\n",
    "main_dir_path = 'D:\\Politecnico di Milano\\Documentale DENG - PRIN-MIMO\\Models\\pyESM_docs\\case_studies'\n",
    "\n",
    "model = esm.Model(\n",
    "    model_dir_name=model_dir_name,\n",
    "    main_dir_path=main_dir_path,\n",
    "    log_level='debug',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after filling sets.xlsx file: \n",
    "# - loading model coordinates to Index\n",
    "# - generating sqlite database tables for sets and variables\n",
    "# (variables tables in sqlite database empty)\n",
    "# (error occurring at the first run related to foreign_keys. second run works)\n",
    "model.load_model_coordinates()\n",
    "model.initialize_blank_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after filling input_data file/s:\n",
    "# - loading input data into sqlite database variables tables\n",
    "# - initialize problem \n",
    "model.load_data_files_to_database()\n",
    "model.initialize_problem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - - \n",
    "MODEL GENERATION FROM EXISTING DATA\n",
    "\n",
    "Generation of a new model working with existing database and data input files.\n",
    "\n",
    "(settings -> model -> use_existing_data -> True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | Model | 'Model' object initialization...\n",
      "INFO | Model.file_manager | 'FileManager' object generated.\n",
      "INFO | Model | Model directory and required setup files exist.\n",
      "INFO | Model | Loading settings.\n",
      "DEBUG | Model.file_manager | File 'settings.yml' loaded.\n",
      "INFO | Model | Loading paths from settings.\n",
      "INFO | Model.core | 'Core' object initialization...\n",
      "INFO | Model.core.sql_manager | 'SQLManager' object generation.\n",
      "INFO | Model.core.index | 'Index' object initialization...\n",
      "DEBUG | Model.file_manager | File 'sets_structure.yml' loaded.\n",
      "DEBUG | Model.file_manager | File 'variables.yml' loaded.\n",
      "DEBUG | Model.core.index | Loading 'variables_fields' to Index.\n",
      "DEBUG | Model.core.index | Loading variables 'table_headers' to Index.\n",
      "DEBUG | Model.core.index | Loading variables 'sets_parsing_hierarchy' to Index.\n",
      "INFO | Model.core.index | 'Index' object initialized.\n",
      "INFO | Model.core.database | 'Database' object initialization...\n",
      "INFO | Model.core.database | 'Database' object initialized.\n",
      "INFO | Model.core.problem | 'Problem' object initialization...\n",
      "INFO | Model.core.problem | 'Problem' object initialized.\n",
      "INFO | Model.core | 'Core' initialized.\n",
      "INFO | Model | Loading existing sets data and variable coordinates.\n",
      "INFO | Model.core.index | 'Index' object: loading new Sets to Index.\n",
      "DEBUG | Model.file_manager | Excel file 'sets.xlsx' loaded.\n",
      "DEBUG | Model.core.index | Loading variables 'coordinates' to Index.\n",
      "DEBUG | Model.core.index | Loading tables 'foreign_keys' to Index.\n",
      "INFO | Model | Initializing numerical problem.\n",
      "INFO | Model.core | Initialize variables dataframes (cvxpy objects, filters dictionaries).\n",
      "DEBUG | Model.core.problem | Generating variable 'd' dataframe (cvxpy object, filter dictionary).\n",
      "DEBUG | Model.core.problem | Generating variable 'u' dataframe (cvxpy object, filter dictionary).\n",
      "DEBUG | Model.core.problem | Generating variable 'Y' dataframe (cvxpy object, filter dictionary).\n",
      "DEBUG | Model.core.problem | Generating variable 'Q' dataframe (cvxpy object, filter dictionary).\n",
      "DEBUG | Model.core.problem | Generating variable 'X' dataframe (cvxpy object, filter dictionary).\n",
      "DEBUG | Model.core.sql_manager | Connection to 'database.db' opened.\n",
      "INFO | Model.core | Fetching data from 'database.db' to cvxpy exogenous variables.\n",
      "DEBUG | Model.core | Fetching data from table 'd' to cvxpy exogenous variable.\n",
      "DEBUG | Model.core | Fetching data from table 'u' to cvxpy exogenous variable.\n",
      "DEBUG | Model.core | Fetching data from table 'Y' to cvxpy exogenous variable.\n",
      "DEBUG | Model.core.sql_manager | Connection to 'database.db' closed.\n",
      "INFO | Model.pbi_manager | 'PBIManager' object generated.\n",
      "INFO | Model | 'Model' object initialized.\n"
     ]
    }
   ],
   "source": [
    "# generate model instance based on setup files filled by the user.\n",
    "# validates model directory (in case user relies on existing directory). \n",
    "# parse settings and paths.\n",
    "# loading model coordinates\n",
    "# initializing numerical problem\n",
    "from src.frontend import esm\n",
    "\n",
    "model_dir_name = '0_hsut'\n",
    "main_dir_path = 'D:\\Politecnico di Milano\\Documentale DENG - PRIN-MIMO\\Models\\pyESM_docs\\case_studies'\n",
    "\n",
    "model = esm.Model(\n",
    "    model_dir_name=model_dir_name,\n",
    "    main_dir_path=main_dir_path,\n",
    "    log_level='debug',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "MODEL USE \n",
    "\n",
    "solving numerical model, results export to sqlite database, generation of powerbi\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case of modifications in input data files (not in sets),\n",
    "# update database and problem\n",
    "model.update_database_and_problem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once model has successfully solved, load endogenous parameters data to \n",
    "# sqlite database and generate powerbi dataset.\n",
    "model.load_results_to_database()\n",
    "model.generate_pbi_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - - \n",
    "TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.core.problem.load_symbolic_problem_from_file()\n",
    "model.core.problem.symbolic_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG | Model.core.problem | Defining numeric problems based on symbolic problem.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'scenarios'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\esm\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'scenarios'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_problems_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mproblem\u001b[38;5;241m.\u001b[39mnumeric_problems\n",
      "File \u001b[1;32md:\\git_repos\\pyesm\\src\\backend\\problem.py:213\u001b[0m, in \u001b[0;36mProblem.generate_problems_dataframe\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    205\u001b[0m     util\u001b[38;5;241m.\u001b[39madd_column_to_dataframe(\n\u001b[0;32m    206\u001b[0m         dataframe\u001b[38;5;241m=\u001b[39mproblem_data,\n\u001b[0;32m    207\u001b[0m         column_header\u001b[38;5;241m=\u001b[39mitem,\n\u001b[0;32m    208\u001b[0m         column_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    209\u001b[0m     )\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m problem_data\u001b[38;5;241m.\u001b[39mindex:\n\u001b[1;32m--> 213\u001b[0m     problem_info \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    214\u001b[0m         problem_data\u001b[38;5;241m.\u001b[39mloc[row][set_name]\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m set_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mlist_sets_split_problem\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m    216\u001b[0m     ]\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefining numeric problem for set/s: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproblem_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    221\u001b[0m     problem_data\u001b[38;5;241m.\u001b[39mat[row, headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblem_info\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m problem_info\n",
      "File \u001b[1;32md:\\git_repos\\pyesm\\src\\backend\\problem.py:214\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    205\u001b[0m     util\u001b[38;5;241m.\u001b[39madd_column_to_dataframe(\n\u001b[0;32m    206\u001b[0m         dataframe\u001b[38;5;241m=\u001b[39mproblem_data,\n\u001b[0;32m    207\u001b[0m         column_header\u001b[38;5;241m=\u001b[39mitem,\n\u001b[0;32m    208\u001b[0m         column_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    209\u001b[0m     )\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m problem_data\u001b[38;5;241m.\u001b[39mindex:\n\u001b[0;32m    213\u001b[0m     problem_info \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 214\u001b[0m         \u001b[43mproblem_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mset_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m set_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mlist_sets_split_problem\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m    216\u001b[0m     ]\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefining numeric problem for set/s: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproblem_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    221\u001b[0m     problem_data\u001b[38;5;241m.\u001b[39mat[row, headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblem_info\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m problem_info\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\esm\\lib\\site-packages\\pandas\\core\\series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\esm\\lib\\site-packages\\pandas\\core\\series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\esm\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'scenarios'"
     ]
    }
   ],
   "source": [
    "model.core.problem.generate_problems_dataframe()\n",
    "model.core.problem.numeric_problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.support import util\n",
    "variable_test = model.core.index.variables.Y\n",
    "\n",
    "var_df_test = util.unpivot_dict_to_dataframe(\n",
    "    data_dict=variable_test.coordinates,\n",
    "    key_order=variable_test.sets_parsing_hierarchy.values()\n",
    ")\n",
    "variable_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "# Problem data.\n",
    "m = 30\n",
    "n = 20\n",
    "np.random.seed(1)\n",
    "A = np.random.randn(m, n)\n",
    "b = np.random.randn(m)\n",
    "\n",
    "# Construct the problem.\n",
    "x = cp.Variable(n)\n",
    "objective = cp.Minimize(cp.sum_squares(A @ x - b))\n",
    "constraints = [0 <= x, x <= 1]\n",
    "prob = cp.Problem(objective, constraints)\n",
    "\n",
    "# The optimal objective value is returned by `prob.solve()`.\n",
    "result = prob.solve()\n",
    "# The optimal value for x is stored in `x.value`.\n",
    "print(x.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import constants\n",
    "\n",
    "row = 0\n",
    "variables = model.core.index.variables\n",
    "\n",
    "allowed_variables = {\n",
    "    variables[var].symbol: variables[var].data['variable'][row]\n",
    "    for var in variables.keys()\n",
    "}\n",
    "allowed_operations = constants._ALLOWED_OPERATORS\n",
    "global_vars = {**allowed_operations, **allowed_variables}\n",
    "\n",
    "model.core.problem.load_symbolic_problem_from_file()\n",
    "objective_code = model.core.problem.symbolic_problem['objective']\n",
    "constraints_code = model.core.problem.symbolic_problem['constraints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = []\n",
    "\n",
    "for code in constraints_code:\n",
    "    local_vars = {}\n",
    "    \n",
    "    exec(\n",
    "        'expression = ' + code, \n",
    "        global_vars, \n",
    "        local_vars\n",
    "    )\n",
    "\n",
    "    constraints.append(local_vars['expression'])\n",
    "\n",
    "constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.util import constants\n",
    "from src.util import util\n",
    "\n",
    "field_id = constants._STD_ID_FIELD['id'][0]\n",
    "\n",
    "col_to_update = constants._STD_VALUES_FIELD['values'][0]\n",
    "cols_common = list(variable.coordinates.keys())\n",
    "\n",
    "new_df = variable.reshaping_variable_data(0)\n",
    "\n",
    "new_values = {\n",
    "    's_Name': 'Reference',\n",
    "    'dt_Name': '2023',\n",
    "    't_Name': 'Final demand',\n",
    "    'values': 15.0\n",
    "}\n",
    "\n",
    "new_df.loc[len(new_df)] = new_values\n",
    "new_df.at[0,'values'] = 2\n",
    "\n",
    "test.core.sqltools.open_connection()\n",
    "existing_df = test.core.sqltools.table_to_dataframe(table_name=variable.symbol)\n",
    "existing_df.drop(columns=['id'],inplace=True)\n",
    "test.core.sqltools.close_connection()\n",
    "\n",
    "print('\\n')\n",
    "print('existing_df: \\n', existing_df)\n",
    "print('\\n')\n",
    "print('new_df: \\n', new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable=test.core.index.variables.u\n",
    "\n",
    "test.core.database.sqltools.open_connection()\n",
    "raw_data = test.core.database.sqltools.filtered_table_to_dataframe(\n",
    "    table_name=variable.symbol,\n",
    "    filters_dict=variable.data['filter'][0]\n",
    ")\n",
    "test.core.database.sqltools.close_connection()\n",
    "\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.core.database.sqltools.open_connection()\n",
    "\n",
    "var = test.core.database.sqltools.filtered_table_to_dataframe(\n",
    "    table_name='u',\n",
    "    filters_dict={\n",
    "        's_Name': ['Reference'],\n",
    "        'dt_Name': [2023],\n",
    "        'f_Name': ['Energy', 'Steel'],\n",
    "        't_Name': ['PV power plant', 'Steel factory', 'Gas power plant']\n",
    "    }\n",
    ")\n",
    "\n",
    "# filter_1 = test.core.database.sqltools.get_related_table_keys(\n",
    "#     child_column_name='f_Name',\n",
    "#     parent_table_name='_set_FLOWS',\n",
    "#     parent_table_fields={\n",
    "#         'f_Category': ['Product flow'],\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# filter_2 = test.core.database.sqltools.get_related_table_keys(\n",
    "#     child_column_name='dt_Name',\n",
    "#     parent_table_name='_set_DATETIME',\n",
    "#     parent_table_fields={\n",
    "#         'dt_Name': [2023],\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# var_custom_filter = test.core.database.sqltools.filtered_table_to_dataframe(\n",
    "#     table_name='v',\n",
    "#     filters_dict={\n",
    "#         **filter_1,\n",
    "#         **filter_2,\n",
    "#         **{'f_Name': ['Steel']},\n",
    "#     }\n",
    "# )\n",
    "\n",
    "test.core.database.sqltools.close_connection()\n",
    "\n",
    "# filter_1, filter_2\n",
    "var"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
